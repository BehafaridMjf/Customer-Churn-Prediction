# -*- coding: utf-8 -*-
"""AI Project Final.ipynb

Automatically generated by Colaboratory

Original file is located at
    https://colab.research.google.com/drive/1Wbv4brir6DzjmF_-6v7KIa0_E7MEtEDt
"""

import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import KFold
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from sklearn.metrics import confusion_matrix
from sklearn.svm import SVC

df1 = pd.read_excel('Telco_customer_churn_demographics.xlsx')
df2 = pd.read_excel('Telco_customer_churn_location.xlsx')
df3 = pd.read_excel('Telco_customer_churn_population.xlsx')
df4 = pd.read_excel('Telco_customer_churn_services.xlsx')
df5 = pd.read_excel('Telco_customer_churn_status.xlsx')
df6 = pd.read_excel('Telco_customer_churn.xlsx')

#renaming columns so they all have same name
df6.rename(columns={"CustomerID": "Customer ID"}, inplace = True)

dataframes = [df2,df4,df5,df6]
df = df1
for i in dataframes:
    df = df.merge(i, how = 'inner', on = 'Customer ID',suffixes=('', '_DROP')).filter(regex='^(?!.*_DROP)')
df = df.merge(df3, how = 'inner', on = 'Zip Code')

df = df.drop(columns = ['CLTV','ID','Population','Satisfaction Score','Churn Score','Lat Long','Latitude','Longitude','Country','State','City','Zip Code','Quarter','Customer Status','Churn Category','Churn Reason','Churn Label'])

for i in df.columns:
    if len(df[i].unique()) == 2:
        print(i)
        df[i].replace(['Yes','No','Female','Male'], [1,0,1,0], inplace= True)

features_ohe = ['Offer','Internet Type','Multiple Lines', 'Internet Service', 'Device Protection', 'Tech Support', 'Contract', 'Payment Method']

df = pd.get_dummies(df, columns=features_ohe)

df.iloc[:,1:].astype(float)

"""### Normalize and Scale"""

features_mms = []
for i in df.columns[1:]:
    if len(df[i].unique()) != 2:
        features_mms.append(i)

def scaling(dataframe, features):
    df_features_mms = pd.DataFrame(dataframe, columns=features_mms)
    df_remaining_features = dataframe.drop(columns=features_mms)

    mms = MinMaxScaler()
    rescaled_features = mms.fit_transform(df_features_mms)

    df_rescaled_features = pd.DataFrame(rescaled_features, columns=features_mms, index=df_remaining_features.index)

    dataframe = pd.concat([df_remaining_features, df_rescaled_features], axis=1)
    return dataframe

df = scaling(df,features_mms)

# change the position of y
Churn = df['Churn Value']
df = df.drop(columns = 'Churn Value')
df.insert(59,'Churn Value',Churn)

"""### Check for Imbalancy"""

y_pos1 = len(df.loc[df['Churn Value'] == 1])
y_pos0 = len(df.loc[df['Churn Value'] == 0])
y_pos = [y_pos1, y_pos0]
plt.bar(['Yes','No'], y_pos, align='center', color = 'purple', alpha=0.5)
plt.ylabel('Count')
plt.title('Churn')

plt.show()

"""#### But first let's find the appropriate K for K fold to use in LR"""

#find value of K
avg_acc_score = []
for k in range(2,11):
    kf = KFold(n_splits=k,random_state=None)
    model = LogisticRegression()

    acc_score = []
    X = df.iloc[:,1:59]
    y = df.iloc[:,59]
    for train_index , test_index in kf.split(X):
        X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]
        y_train , y_test = y[train_index] , y[test_index]

        model.fit(X_train,y_train)
        pred_values = model.predict(X_test)

        acc = accuracy_score(pred_values , y_test)
        acc_score.append(acc)

    avg_acc_score.append((sum(acc_score)/k))
max_value = max(avg_acc_score)
max_index = avg_acc_score. index(max_value)
k = max_index + 2
score = avg_acc_score[k-2]
print(k)

k = [2,3,4,5,6,7,8,9,10]
plt.plot(k,avg_acc_score)
plt.xlabel('Number of K')
plt.ylabel('Accuracy')

"""### Check if UnderSamling or OverSampling or Smote will increase the accuracy"""

# The performance of these algorithms were compared based on the Misclassification cost in Logistic Regression(10fold)

df3 = df.copy()
df2 = df.copy()

import seaborn as sns
from imblearn.over_sampling import RandomOverSampler
X = df2.iloc[:,1:59]
y = df2.iloc[:,59]
ros = RandomOverSampler(random_state=0)
X_resampled, y_resampled = ros.fit_resample(X, y)

from imblearn.under_sampling import RandomUnderSampler
X = df3.iloc[:,1:59]
y = df3.iloc[:,59]
ros = RandomUnderSampler(random_state=0)
X_resampled, y_resampled = ros.fit_resample(X, y)

from imblearn.over_sampling import SMOTE
seed = 100
k  = 15
X = df2.iloc[:,1:59]
y = df2.iloc[:,59]
sm = SMOTE(sampling_strategy='auto', k_neighbors=k, random_state=seed)
X_resampled, y_resampled = sm.fit_resample(X, y)

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier


avg_acc_score = []

k = 10
kf = KFold(n_splits=k,random_state=None)

# clf = [LogisticRegression(), SVC(),GradientBoostingClassifier(),RandomForestClassifier(n_estimators=10),BaggingClassifier(base_estimator=LogisticRegression(), n_estimators=10, random_state=0),BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=0),]
clf = [LogisticRegression()]
for model in clf : 
    acc_score = []
    fn_list = []
    fp_list = []
    tp_list = []
    tn_list = []
    X = X_resampled.copy()
    y = y_resampled.copy()
#     X = df.iloc[:,1:59]
#     y = df.iloc[:,59]

    for train_index , test_index in kf.split(X):
        X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]
        y_train , y_test = y[train_index] , y[test_index]

        model.fit(X_train,y_train)
        pred_values = model.predict(X_test)


        acc = accuracy_score(pred_values , y_test)
        acc_score.append(acc)
        actual = y_test
        predicted = pred_values

        tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)
        fn_list.append(fn)
        fp_list.append(fp)
        tp_list.append(tp)
        tn_list.append(tn)


    print(f'False Negatives in {model} : \n', sum(fn_list)/k)
    print(f'Misclassification Cost in {model} : \n', (sum(fn_list)/k)/((sum(tp_list)/k) + (sum(fn_list)/k)))
    print(f'False Positives in {model} : \n', sum(fp_list)/k)


    avg_acc_score= sum(acc_score)/k
    print(avg_acc_score)
    print(acc_score)

"""### SMOTE gives the lowest Misclassification Cost so it would be implemented.

### Now Let's Check if Customer Segmentation is going to reduce the cost for us(our goal)
"""

from sklearn.cluster import KMeans

X = X_resampled.copy()
y = y_resampled.copy()

# Find the Value for K using Elbow method

distortions = []
K = range(1,10)
for k in K:
    kmeanModel = KMeans(n_clusters=k)
    kmeanModel.fit(X)
    distortions.append(kmeanModel.inertia_)

plt.figure(figsize=(8,4))
plt.plot(K, distortions, 'bx-')
plt.xlabel('k')
plt.ylabel('Distortion')
plt.title('The Elbow Method showing the optimal k')
plt.show()

# Let's choose k = 3

kmeans = KMeans(n_clusters=3)
kmeans.fit(X)

X.insert(58,'cluster',kmeans.labels_)

y = pd.DataFrame(y)
y.insert(1,'cluster',kmeans.labels_)

# Compare if clustering is helping us reduce the misclassification cost(with LR)

X_df = X.copy()
y_df = y.copy()

from sklearn.linear_model import LogisticRegression
# from sklearn.ensemble import BaggingClassifier
# from sklearn.ensemble import RandomForestClassifier
# from sklearn.ensemble import GradientBoostingClassifier

avg_acc_score = []

k = 10
kf = KFold(n_splits=k,random_state=None)

# clf = [LogisticRegression(), SVC(),GradientBoostingClassifier(),RandomForestClassifier(n_estimators=10),BaggingClassifier(base_estimator=LogisticRegression(), n_estimators=10, random_state=0),BaggingClassifier(base_estimator=SVC(), n_estimators=10, random_state=0),]
clf = [LogisticRegression()]
for model in clf : 
    acc_score = []
    fn_list = []
    fp_list = []
    tn_list = []
    tp_list = []
    fn_cluster = 0
    tp_cluster = 0
#     X = X_resampled.copy()
#     y = y_resampled.copy()
#     X = df.iloc[:,1:59]
#     y = df.iloc[:,59]
    all_fn = 0
    for cluster in range(0,3):
        X = X_df.loc[X_df['cluster'] == cluster].reset_index(drop = True)
        y = y_df.loc[y_df['cluster'] == cluster]['Churn Value'].reset_index(drop = True)
    
        fn_list = []
    
    
        for train_index , test_index in kf.split(X):
            X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]
            y_train , y_test = y[train_index] , y[test_index]

            model.fit(X_train,y_train)
            pred_values = model.predict(X_test)


            acc = accuracy_score(pred_values , y_test)
            acc_score.append(acc)
            actual = y_test
            predicted = pred_values

            tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)
            fn_list.append(fn)
            fp_list.append(fp)
            tp_list.append(tp)
            tn_list.append(tn)
        fn_cluster = fn_cluster + sum(fn_list)/k
        tp_cluster = tp_cluster + sum(tp_list)/k
        fn_cluster = fn_cluster + sum(fn_list)/k
        all_fn = all_fn + (sum(fn_list)/k)
        print(all_fn)



    print(f'False Negatives in {model} : \n', sum(fn_list)/k)
    print(f'Misclassification Cost in {model} : \n', fn_cluster/(fn_cluster + tp_cluster))
    print(f'False Positives in {model} : \n', sum(fp_list)/k)
#     print(f'False Negatives in {model} : \n', sum(fn_list)/k)
#     print(f'False Positives in {model} : \n', sum(fp_list)/k)
#     print(f'False Negatives in {model} : \n', fn_list)
#     print(f'False Positives in {model} : \n', fp_list)

#     avg_acc_score= sum(acc_score)/k
#     print(avg_acc_score)
#     print(acc_score)

# Unfortunately Clustering didn't help us in reducing the misclassification cost!

"""### So let's proceed to comparing the algorithms"""

from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier


avg_acc_score = []

k = 10
kf = KFold(n_splits=k,random_state=None)

clf = [LogisticRegression(),DecisionTreeClassifier(), GradientBoostingClassifier(n_estimators = 10),RandomForestClassifier(n_estimators=10),BaggingClassifier(base_estimator=LogisticRegression(), n_estimators=10, random_state=0)]
misc = []
fns = []
for model in clf : 
    acc_score = []
    fn_list = []
    fp_list = []
    tp_list = []
    tn_list = []
    X = X_resampled.copy()
    y = y_resampled.copy()
#     X = df.iloc[:,1:59]
#     y = df.iloc[:,59]

    for train_index , test_index in kf.split(X):
        X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]
        y_train , y_test = y[train_index] , y[test_index]

        model.fit(X_train,y_train)
        pred_values = model.predict(X_test)


        acc = accuracy_score(pred_values , y_test)
        acc_score.append(acc)
        actual = y_test
        predicted = pred_values

        tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)
        fn_list.append(fn)
        fp_list.append(fp)
        tp_list.append(tp)
        tn_list.append(tn)
   

#     print(f'False Negatives in {model} : \n', sum(fn_list)/k)
#     print(f'False Positives in {model} : \n', sum(fp_list)/k)
#     print(f'Misclassification Cost in {model} : \n', (sum(fn_list)/k)/((sum(tp_list)/k) + (sum(fn_list)/k)))
    misc.append((sum(fn_list)/k)/((sum(tp_list)/k) + (sum(fn_list)/k)))
    fns.append( sum(fn_list)/k)


#     print(f'False Negatives in {model} : \n', fn_list)
#     print(f'False Positives in {model} : \n', fp_list)

#     avg_acc_score= sum(acc_score)/k
#     print(avg_acc_score)
#     print(acc_score)
clfs = ['LR', 'DT', 'GB','RF','Bagging']    
plt.plot(clfs,misc*100, color ='blue', label = 'Misclassification Cost')
plt.plot(clfs,fns, color ='red', label = '#False Negatives')
plt.legend()

miscnew = []
for i in misc:
    miscnew.append(i * 100)
clfs = ['LR', 'DT', 'GB','RF','Bagging']    
plt.plot(clfs,miscnew, color ='blue', label = 'Misclassification Cost')
plt.plot(clfs,fns, color ='red', label = '#False Negatives')
plt.legend()

gradient_booster = GradientBoostingClassifier(n_estimators = 10 , learning_rate=1)

avg_acc_score = []

k = 10
kf = KFold(n_splits=k,random_state=None)

clf = [gradient_booster]

f_list = [5,10,20,50,70,100,150,200]
misc = []
for f in f_list : 
    model = GradientBoostingClassifier(n_estimators = f , learning_rate=0.1)
    acc_score = []
    fn_list = []
    fp_list = []
    tp_list = []
    tn_list = []
    X = X_resampled.copy()
    y = y_resampled.copy()
#     X = df.iloc[:,1:59]
#     y = df.iloc[:,59]

    for train_index , test_index in kf.split(X):
        X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]
        y_train , y_test = y[train_index] , y[test_index]

        model.fit(X_train,y_train)
        pred_values = model.predict(X_test)


        acc = accuracy_score(pred_values , y_test)
        acc_score.append(acc)
        actual = y_test
        predicted = pred_values

        tp, fn, fp, tn = confusion_matrix(actual,predicted,labels=[1,0]).reshape(-1)
        fn_list.append(fn)
        fp_list.append(fp)
        tp_list.append(tp)
        tn_list.append(tn)
   

    print(f'False Negatives in {model} : \n', sum(fn_list)/k)
    print(f'False Positives in {model} : \n', sum(fp_list)/k)
    print(f'Misclassification Cost in {model} : \n', (sum(fn_list)/k)/((sum(tp_list)/k) + (sum(fn_list)/k)))
    misc.append(100 * (sum(fn_list)/k)/((sum(tp_list)/k) + (sum(fn_list)/k)))


    print(f'False Negatives in {model} : \n', fn_list)
    print(f'False Positives in {model} : \n', fp_list)

    avg_acc_score= sum(acc_score)/k
    print(avg_acc_score)
    print(acc_score)

plt.plot(f_list,misc)
plt.xlabel('Number of Base Estimators')
plt.ylabel('Misclassification Cost')

gradient_booster.get_params(deep=True)

misc = [64.30228063393892,11.364514882102822,13.877077696173173,13.12330885195207,12.833397758020876,13.297255508310785]
n = [0.01,0.1,0.3,0.5,0.7,1]

plt.plot(n,misc)
plt.xlabel('Learning Rate')
plt.ylabel('Misclassification Cost')

